{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78406c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "import numpy as np\n",
    "import ntpath\n",
    "import re\n",
    "import time\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db8c5fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (200,200,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b70056",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50V2(\n",
    "    input_shape=input_shape, include_top=False, weights='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867d33a9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 206, 206, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 100, 100, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 102, 102, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 50, 50, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 50, 50, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 50, 50, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 50, 50, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 50, 50, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 52, 52, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 50, 50, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 50, 50, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 50, 50, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 50, 50, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 50, 50, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 50, 50, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 50, 50, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 52, 52, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 50, 50, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 50, 50, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 50, 50, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 50, 50, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 50, 50, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 50, 50, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 50, 50, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 52, 52, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 25, 25, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 25, 25, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 25, 25, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 25, 25, 256)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 25, 25, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 25, 25, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 25, 25, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 25, 25, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 27, 27, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 25, 25, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 25, 25, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 25, 25, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 25, 25, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 25, 25, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 25, 25, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 25, 25, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 25, 25, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 27, 27, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 25, 25, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 25, 25, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 25, 25, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 25, 25, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 25, 25, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 25, 25, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 25, 25, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 27, 27, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 25, 25, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 25, 25, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 25, 25, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 25, 25, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 25, 25, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 25, 25, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 25, 25, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 27, 27, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 13, 13, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 13, 13, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 13, 13, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 13, 13, 512)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 13, 13, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 13, 13, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 13, 13, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 13, 13, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 15, 15, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 13, 13, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 13, 13, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 13, 13, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 13, 13, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 13, 13, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 13, 13, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 13, 13, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 13, 13, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 15, 15, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 13, 13, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 13, 13, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 13, 13, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 13, 13, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 13, 13, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 13, 13, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 13, 13, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 15, 15, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 13, 13, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 13, 13, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 13, 13, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 13, 13, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 13, 13, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 13, 13, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 13, 13, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 15, 15, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 13, 13, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 13, 13, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 13, 13, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 13, 13, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 13, 13, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 13, 13, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 13, 13, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 15, 15, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 13, 13, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 13, 13, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 13, 13, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 13, 13, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 13, 13, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 13, 13, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 13, 13, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 15, 15, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,564,800\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05256f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.models.Sequential(\n",
    "  [\n",
    "   tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "                                                 input_shape = input_shape),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ee2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "x = data_augmentation(inputs)\n",
    "# x = preprocess_input(inputs)\n",
    "x = base_model(x, training=True)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bdd687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.001),\n",
    "              loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "973925a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 200, 200, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50v2 (Functional)      (None, 7, 7, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 23,566,849\n",
      "Trainable params: 23,521,409\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0edf5195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b830d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDatagen:\n",
    "    def __init__(self, img_dir: str, label_dir: str, val_size: int):\n",
    "        \n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.val_size = val_size\n",
    "        self.img_paths = self.__generate_paths(path_img, \"*.png\")\n",
    "\n",
    "\n",
    "    def get_training_generators(self, batch_size: int):\n",
    "        \n",
    "        train_gen = DataGenerator(label_path = path_labels, batch_size = 64,\n",
    "                                  img_paths = self.img_paths[:len(self.img_paths) - self.val_size])\n",
    "        valid_gen = DataGenerator(label_path = path_labels, batch_size = 64,\n",
    "                                  img_paths = self.img_paths[len(self.img_paths) - self.val_size:])\n",
    "\n",
    "        return train_gen, valid_gen\n",
    "    \n",
    "    def __generate_paths(self, path, pattern):\n",
    "        return glob.glob(path + pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b95d044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, label_path: str, batch_size: int, img_paths):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.image_paths = img_paths\n",
    "        self.label_df = self.__generate_label_df(label_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.image_paths) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        from_idx = index * self.batch_size\n",
    "        to_idx =  len(self.image_paths) if (index + 1) * self.batch_size > len(self.image_paths) else (index + 1) * self.batch_size\n",
    "        image_paths = self.image_paths[from_idx : to_idx]      \n",
    "        \n",
    "        data_train = []\n",
    "        data_labels = []\n",
    "        for image_path in image_paths:\n",
    "            image_name = ntpath.basename(image_path)\n",
    "            ticker, label_idx = self.__get_ticker_index(image_name)\n",
    "            img = cv2.imread(image_path)\n",
    "            data_train.append(img)\n",
    "            data_labels.append(self.label_df[ticker].loc[int(label_idx) - 1])\n",
    "            \n",
    "        return np.multiply(np.asarray(data_train),1/255), np.asarray(data_labels)\n",
    "\n",
    "    def __generate_paths(self, path, pattern):\n",
    "        \"\"\"\n",
    "            Creates an array of paths\n",
    "        \"\"\"\n",
    "        return glob.glob(path + pattern)\n",
    "        \n",
    "    def __generate_label_df(self, label_path):\n",
    "        labels_paths = self.__generate_paths(label_path, \"*.rda\")\n",
    "#         print(labels_paths)\n",
    "        labels_df = pd.DataFrame()\n",
    "        \n",
    "        for label_file_path in labels_paths:\n",
    "            label_file_name = ntpath.basename(label_file_path)\n",
    "            label_df = pyreadr.read_r(label_file_path)\n",
    "            ticker = label_file_name[:label_file_name.rfind('-')]\n",
    "            labels_df[ticker] = label_df['labels']['labels'].to_numpy()\n",
    "        \n",
    "        return labels_df \n",
    "    \n",
    "    def __get_ticker_index(self, s):\n",
    "        head = s.split('.')[0].rstrip('0123456789')\n",
    "        tail = s[len(head):len(s) - 4]\n",
    "        return head, tail\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.images = random.shuffle(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb8a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = \"/mnt/data/home/kantek/wu/data/img/\"\n",
    "path_labels = \"/mnt/data/home/kantek/wu/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93f8bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = \"/tmp/img_data/img/\"\n",
    "path_labels = \"/tmp/img_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34b6fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = StockDatagen(path_img, path_labels, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bec5bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, valid_gen = datagen.get_training_generators(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9503259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch <= 2:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7931b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ac9911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "2842/2842 [==============================] - 905s 319ms/step - loss: 0.6912 - accuracy: 0.5276 - precision_2: 0.5313 - recall_2: 0.5918 - auc_2: 0.5389 - val_loss: 0.6803 - val_accuracy: 0.5577 - val_precision_2: 0.5698 - val_recall_2: 0.6652 - val_auc_2: 0.5839\n",
      "Epoch 2/8\n",
      "2842/2842 [==============================] - 906s 319ms/step - loss: 0.6788 - accuracy: 0.5639 - precision_2: 0.5687 - recall_2: 0.5837 - auc_2: 0.5918 - val_loss: 0.6630 - val_accuracy: 0.5895 - val_precision_2: 0.5993 - val_recall_2: 0.6730 - val_auc_2: 0.6250\n",
      "Epoch 3/8\n",
      "2842/2842 [==============================] - 908s 319ms/step - loss: 0.6534 - accuracy: 0.6060 - precision_2: 0.6088 - recall_2: 0.6269 - auc_2: 0.6519 - val_loss: 0.6347 - val_accuracy: 0.6227 - val_precision_2: 0.6227 - val_recall_2: 0.7256 - val_auc_2: 0.6771\n",
      "Epoch 4/8\n",
      "2842/2842 [==============================] - 908s 319ms/step - loss: 0.6157 - accuracy: 0.6472 - precision_2: 0.6498 - recall_2: 0.6616 - auc_2: 0.7107 - val_loss: 0.6158 - val_accuracy: 0.6356 - val_precision_2: 0.6446 - val_recall_2: 0.6921 - val_auc_2: 0.7015\n",
      "Epoch 5/8\n",
      "2842/2842 [==============================] - 909s 320ms/step - loss: 0.5709 - accuracy: 0.6883 - precision_2: 0.6909 - recall_2: 0.6987 - auc_2: 0.7647 - val_loss: 0.5899 - val_accuracy: 0.6662 - val_precision_2: 0.6712 - val_recall_2: 0.7222 - val_auc_2: 0.7405\n",
      "Epoch 6/8\n",
      "2842/2842 [==============================] - 906s 319ms/step - loss: 0.5202 - accuracy: 0.7285 - precision_2: 0.7312 - recall_2: 0.7356 - auc_2: 0.8135 - val_loss: 0.5647 - val_accuracy: 0.6963 - val_precision_2: 0.7085 - val_recall_2: 0.7224 - val_auc_2: 0.7750\n",
      "Epoch 7/8\n",
      "2842/2842 [==============================] - 907s 319ms/step - loss: 0.4630 - accuracy: 0.7672 - precision_2: 0.7714 - recall_2: 0.7695 - auc_2: 0.8576 - val_loss: 0.5514 - val_accuracy: 0.7135 - val_precision_2: 0.7271 - val_recall_2: 0.7328 - val_auc_2: 0.7989\n",
      "Epoch 8/8\n",
      "2842/2842 [==============================] - 907s 319ms/step - loss: 0.4007 - accuracy: 0.8070 - precision_2: 0.8097 - recall_2: 0.8104 - auc_2: 0.8967 - val_loss: 0.5318 - val_accuracy: 0.7402 - val_precision_2: 0.7339 - val_recall_2: 0.7978 - val_auc_2: 0.8277\n"
     ]
    }
   ],
   "source": [
    "history20 = model.fit(train_gen,\n",
    "                    validation_data = valid_gen,\n",
    "                    epochs = 8,\n",
    "                    callbacks=[callback],\n",
    "                    workers = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc0cce8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "2842/2842 [==============================] - 903s 318ms/step - loss: 0.3485 - accuracy: 0.8371 - precision_2: 0.8406 - recall_2: 0.8382 - auc_2: 0.9235 - val_loss: 0.5290 - val_accuracy: 0.7598 - val_precision_2: 0.7739 - val_recall_2: 0.7706 - val_auc_2: 0.8457\n",
      "Epoch 2/8\n",
      "2842/2842 [==============================] - 904s 318ms/step - loss: 0.3035 - accuracy: 0.8614 - precision_2: 0.8632 - recall_2: 0.8640 - auc_2: 0.9427 - val_loss: 0.5454 - val_accuracy: 0.7723 - val_precision_2: 0.7967 - val_recall_2: 0.7641 - val_auc_2: 0.8546\n",
      "Epoch 3/8\n",
      "2842/2842 [==============================] - 907s 319ms/step - loss: 0.2627 - accuracy: 0.8825 - precision_2: 0.8850 - recall_2: 0.8834 - auc_2: 0.9575 - val_loss: 0.5495 - val_accuracy: 0.7900 - val_precision_2: 0.7896 - val_recall_2: 0.8216 - val_auc_2: 0.8655\n",
      "Epoch 4/8\n",
      "2842/2842 [==============================] - 904s 318ms/step - loss: 0.2162 - accuracy: 0.9062 - precision_2: 0.9076 - recall_2: 0.9076 - auc_2: 0.9714 - val_loss: 0.5595 - val_accuracy: 0.7972 - val_precision_2: 0.8178 - val_recall_2: 0.7930 - val_auc_2: 0.8755\n",
      "Epoch 5/8\n",
      "2842/2842 [==============================] - 908s 320ms/step - loss: 0.1792 - accuracy: 0.9234 - precision_2: 0.9244 - recall_2: 0.9247 - auc_2: 0.9803 - val_loss: 0.5693 - val_accuracy: 0.8043 - val_precision_2: 0.8181 - val_recall_2: 0.8095 - val_auc_2: 0.8803\n",
      "Epoch 6/8\n",
      "2842/2842 [==============================] - 906s 319ms/step - loss: 0.1473 - accuracy: 0.9379 - precision_2: 0.9389 - recall_2: 0.9387 - auc_2: 0.9866 - val_loss: 0.5938 - val_accuracy: 0.8136 - val_precision_2: 0.8199 - val_recall_2: 0.8295 - val_auc_2: 0.8886\n",
      "Epoch 7/8\n",
      "2842/2842 [==============================] - 908s 319ms/step - loss: 0.1272 - accuracy: 0.9466 - precision_2: 0.9478 - recall_2: 0.9469 - auc_2: 0.9899 - val_loss: 0.5924 - val_accuracy: 0.8203 - val_precision_2: 0.8413 - val_recall_2: 0.8135 - val_auc_2: 0.8943\n",
      "Epoch 8/8\n",
      "2842/2842 [==============================] - 908s 320ms/step - loss: 0.1046 - accuracy: 0.9568 - precision_2: 0.9578 - recall_2: 0.9571 - auc_2: 0.9931 - val_loss: 0.6584 - val_accuracy: 0.8224 - val_precision_2: 0.8359 - val_recall_2: 0.8263 - val_auc_2: 0.8930\n"
     ]
    }
   ],
   "source": [
    "history21 = model.fit(train_gen,\n",
    "                    validation_data = valid_gen,\n",
    "                    epochs = 8,\n",
    "                    callbacks=[callback],\n",
    "                    workers = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee183690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2842/2842 [==============================] - 910s 320ms/step - loss: 0.0781 - accuracy: 0.9681 - precision_3: 0.9697 - recall_3: 0.9675 - auc_3: 0.9961 - val_loss: 0.6677 - val_accuracy: 0.8320 - val_precision_3: 0.8392 - val_recall_3: 0.8437 - val_auc_3: 0.8979\n",
      "Epoch 2/4\n",
      "2842/2842 [==============================] - 908s 319ms/step - loss: 0.0676 - accuracy: 0.9726 - precision_3: 0.9740 - recall_3: 0.9720 - auc_3: 0.9971 - val_loss: 0.6932 - val_accuracy: 0.8338 - val_precision_3: 0.8446 - val_recall_3: 0.8400 - val_auc_3: 0.8991\n",
      "Epoch 3/4\n",
      "2842/2842 [==============================] - 908s 319ms/step - loss: 0.0629 - accuracy: 0.9743 - precision_3: 0.9750 - recall_3: 0.9744 - auc_3: 0.9974 - val_loss: 0.7115 - val_accuracy: 0.8332 - val_precision_3: 0.8426 - val_recall_3: 0.8414 - val_auc_3: 0.8970\n",
      "Epoch 4/4\n",
      "2842/2842 [==============================] - 907s 319ms/step - loss: 0.0595 - accuracy: 0.9753 - precision_3: 0.9764 - recall_3: 0.9750 - auc_3: 0.9977 - val_loss: 0.7215 - val_accuracy: 0.8337 - val_precision_3: 0.8433 - val_recall_3: 0.8417 - val_auc_3: 0.8974\n"
     ]
    }
   ],
   "source": [
    "history22 = model.fit(train_gen,\n",
    "                    validation_data = valid_gen,\n",
    "                    epochs = 4,\n",
    "                    callbacks=[callback],\n",
    "                    workers = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370157c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "                    batch_size = 64,\n",
    "                    epochs = 4,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46416ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mobilenetV2_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.00001),\n",
    "              loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cf16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 4,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "history10 = model.fit(X_train,y_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 3,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007968d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "                    batch_size = 64,\n",
    "                    epochs = 4,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ab27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(200,200,3)))\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b2c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "                    batch_size = 64,\n",
    "                    epochs = 4,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('resnet50_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.00001),\n",
    "              loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513636a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model.fit(X_train,y_train,\n",
    "                    batch_size = 16,\n",
    "                    epochs = 4,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ede95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model.fit(X_train,y_train,\n",
    "                    batch_size = 256,\n",
    "                    epochs=4,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
